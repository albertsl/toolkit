{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning: This notebook might be outdated, check the python scrip for the latest version. \n",
    "https://github.com/albertsl/toolkit/blob/master/templates/python%20for%20data%20science.py\n",
    "\n",
    "Albert Sanchez Lafuente 2/4/2019, Pineda de Mar, Spain\n",
    "\n",
    "https://github.com/albertsl/\n",
    "\n",
    "https://www.linkedin.com/in/albertsl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "sns.set()\n",
    "import numba\n",
    "\n",
    "#Check versions\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Numpy version:\", np.version.version)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Seaborn version:\", sns.__version__)\n",
    "print(\"Numba version:\", numba.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv('file.csv')\n",
    "#If data is too big, take a sample of it\n",
    "df = pd.read_csv('file.csv', nrows=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce dataframe memory usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improve execution speed of your code by adding these decorators:\n",
    "@numba.jit\n",
    "def f(x):\n",
    "    return x\n",
    "@numba.njit #The nopython=True option requires that the function be fully compiled (so that the Python interpreter calls are completely removed), otherwise an exception is raised.  These exceptions usually indicate places in the function that need to be modified in order to achieve better-than-Python performance.  We strongly recommend always using nopython=True.\n",
    "def f(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing data\n",
    "total_null = df.isna().sum().sort_values(ascending=False)\n",
    "percent = 100*(df.isna().sum()/df.isna().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total_null, percent], axis=1, keys=['Total', 'Percent'])\n",
    "#Generate new features with missing data\n",
    "df['feature1_nan'] = df['feature1'].isna()\n",
    "df['feature2_nan'] = df['feature2'].isna()\n",
    "#Also look for infinite data, recommended to check it also after feature engineering\n",
    "df.replace(np.inf,0,inplace=True)\n",
    "df.replace(-np.inf,0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicated data\n",
    "df.duplicated().value_counts()\n",
    "df['duplicated'] = df.duplicated() #Create a new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing data or drop columns/rows\n",
    "df.fillna()\n",
    "df.drop('column_full_of_nans')\n",
    "df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize data\n",
    "df.head()\n",
    "df.describe()\n",
    "df.info()\n",
    "df.columns\n",
    "#For a categorical dataset we want to see how many instances of each category there are\n",
    "df['categorical_var'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis (EDA)\n",
    "sns.pairplot(df)\n",
    "sns.distplot(df['column'])\n",
    "sns.countplot(df['column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix or remove outliers\n",
    "sns.boxplot(df['feature1'])\n",
    "sns.boxplot(df['feature2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation analysis\n",
    "sns.heatmap(df.corr(), annot=True, fmt='.2f')\n",
    "correlations = df.corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\n",
    "correlations = correlations[correlations['level_0'] != correlations['level_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode categorical variables\n",
    "#Encoding for target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['categorical_var'] = le.fit_transform(df['categorical_var'])\n",
    "#One hot encoding for categorical information\n",
    "#Use sklearn's OneHotEncoder for categories encoded as possitive real numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "df['var_to_encode'] = enc.fit_transform(df['var_to_encode'])\n",
    "#Use pandas get_dummies for categories encoded as strings\n",
    "pd.get_dummies(df, columns=['col1','col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection: Drop attributes that provide no useful information for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering. Create new features by transforming the data\n",
    "#Discretize continuous features\n",
    "#Decompose features (categorical, date/time, etc.)\n",
    "#Add promising transformations of features (e.g., log(x), sqrt(x), x^2, etc.)\n",
    "#Aggregate features into promising new features (x*y)\n",
    "#For speed/movement data, add vectorial features. Try many different combinations\n",
    "df['position_norm'] = df['position_X'] ** 2 + df['position_Y'] ** 2 + df['position_Z'] ** 2\n",
    "df['position_module'] = df['position_norm'] ** 0.5\n",
    "df['position_norm_X'] = df['position_X'] / df['position_module']\n",
    "df['position_norm_Y'] = df['position_Y'] / df['position_module']\n",
    "df['position_norm_Z'] = df['position_Z'] / df['position_module']\n",
    "df['position_over_velocity'] = df['position_module'] / df['velocity_module']\n",
    "#For time series data: Discretize the data by different samples.\n",
    "from astropy.stats import median_absolute_deviation\n",
    "from statsmodels.robust.scale import mad\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "def CPT5(x):\n",
    "    den = len(x)*np.exp(np.std(x))\n",
    "    return sum(np.exp(x))/den\n",
    "\n",
    "def SSC(x):\n",
    "    x = np.array(x)\n",
    "    x = np.append(x[-1], x)\n",
    "    x = np.append(x, x[1])\n",
    "    xn = x[1:len(x)-1]\n",
    "    xn_i2 = x[2:len(x)]    #xn+1\n",
    "    xn_i1 = x[0:len(x)-2]  #xn-1\n",
    "    ans = np.heaviside((xn-xn_i1)*(xn-xn_i2), 0)\n",
    "    return sum(ans[1:])\n",
    "\n",
    "def wave_length(x):\n",
    "    x = np.array(x)\n",
    "    x = np.append(x[-1], x)\n",
    "    x = np.append(x, x[1])\n",
    "    xn = x[1:len(x)-1]\n",
    "    xn_i2 = x[2:len(x)]    #xn+1\n",
    "    return sum(abs(xn_i2-xn))\n",
    "\n",
    "def norm_entropy(x):\n",
    "    tresh = 3\n",
    "    return sum(np.power(abs(x), tresh))\n",
    "\n",
    "def SRAV(x):\n",
    "    SRA = sum(np.sqrt(abs(x)))\n",
    "    return np.power(SRA/len(x), 2)\n",
    "\n",
    "def mean_abs(x):\n",
    "    return sum(abs(x))/len(x)\n",
    "\n",
    "def zero_crossing(x):\n",
    "    x = np.array(x)\n",
    "    x = np.append(x[-1], x)\n",
    "    x = np.append(x, x[1])\n",
    "    xn = x[1:len(x)-1]\n",
    "    xn_i2 = x[2:len(x)]    #xn+1\n",
    "    return sum(np.heaviside(-xn*xn_i2, 0))\n",
    "\n",
    "df_tmp = pd.DataFrame()\n",
    "for column in tqdm(df.columns):\n",
    "    df_tmp[column + '_mean'] = df.groupby(['series_id'])[column].mean()\n",
    "    df_tmp[column + '_median'] = df.groupby(['series_id'])[column].median()\n",
    "    df_tmp[column + '_max'] = df.groupby(['series_id'])[column].max()\n",
    "    df_tmp[column + '_min'] = df.groupby(['series_id'])[column].min()\n",
    "    df_tmp[column + '_std'] = df.groupby(['series_id'])[column].std()\n",
    "    df_tmp[column + '_range'] = df_tmp[column + '_max'] - df_tmp[column + '_min']\n",
    "    df_tmp[column + '_max_over_Min'] = df_tmp[column + '_max'] / df_tmp[column + '_min']\n",
    "    df_tmp[column + 'median_abs_dev'] = df.groupby(['series_id'])[column].mad()\n",
    "    df_tmp[column + '_mean_abs_chg'] = df.groupby(['series_id'])[column].apply(lambda x: np.mean(np.abs(np.diff(x))))\n",
    "    df_tmp[column + '_mean_change_of_abs_change'] = df.groupby('series_id')[column].apply(lambda x: np.mean(np.diff(np.abs(np.diff(x)))))\n",
    "    df_tmp[column + '_abs_max'] = df.groupby(['series_id'])[column].apply(lambda x: np.max(np.abs(x)))\n",
    "    df_tmp[column + '_abs_min'] = df.groupby(['series_id'])[column].apply(lambda x: np.min(np.abs(x)))\n",
    "    df_tmp[column + '_abs_avg'] = (df_tmp[column + '_abs_min'] + df_tmp[column + '_abs_max'])/2\n",
    "    df_tmp[column + '_abs_mean'] = df.groupby('series_id')[column].apply(lambda x: np.mean(np.abs(x)))\n",
    "    df_tmp[column + '_abs_std'] = df.groupby('series_id')[column].apply(lambda x: np.std(np.abs(x)))\n",
    "    df_tmp[column + '_abs_range'] = df_tmp[column + '_abs_max'] - df_tmp[column + '_abs_min']\n",
    "    df_tmp[column + '_skew'] = df.groupby(['series_id'])[column].skew()\n",
    "    df_tmp[column + '_q25'] = df.groupby(['series_id'])[column].quantile(0.25)\n",
    "    df_tmp[column + '_q75'] = df.groupby(['series_id'])[column].quantile(0.75)\n",
    "    df_tmp[column + '_q95'] = df.groupby(['series_id'])[column].quantile(0.95)\n",
    "    df_tmp[column + '_iqr'] = df_tmp[column + '_q75'] - df_tmp[column + '_q25']\n",
    "    df_tmp[column + '_CPT5'] = df.groupby(['series_id'])[column].apply(CPT5)\n",
    "    df_tmp[column + '_SSC'] = df.groupby(['series_id'])[column].apply(SSC)\n",
    "    df_tmp[column + '_wave_lenght'] = df.groupby(['series_id'])[column].apply(wave_length)\n",
    "    df_tmp[column + '_norm_entropy'] = df.groupby(['series_id'])[column].apply(norm_entropy)\n",
    "    df_tmp[column + '_SRAV'] = df.groupby(['series_id'])[column].apply(SRAV)\n",
    "    df_tmp[column + '_kurtosis'] = df.groupby(['series_id'])[column].apply(kurtosis)\n",
    "    df_tmp[column + '_zero_crossing'] = df.groupby(['series_id'])[column].apply(zero_crossing)\n",
    "    df_tmp[column +  '_unq'] = df[column].round(3).nunique()\n",
    "    try:\n",
    "        df_tmp[column + '_freq'] = df[column].value_counts().idxmax()\n",
    "    except:\n",
    "        df_tmp[column + '_freq'] = 0\n",
    "    df_tmp[column + '_max_freq'] = df[df[column] == df[column].max()].shape[0]\n",
    "    df_tmp[column + '_min_freq'] = df[df[column] == df[column].min()].shape[0]\n",
    "    df_tmp[column + '_pos_freq'] = df[df[column] >= 0].shape[0]\n",
    "    df_tmp[column + '_neg_freq'] = df[df[column] < 0].shape[0]\n",
    "    df_tmp[column + '_nzeros'] = (df[column]==0).sum(axis=0)\n",
    "df = df_tmp.copy()\n",
    "#Create a new column from conditions on other columns\n",
    "df['column_y'] = df[(df['column_x1'] | 'column_x2') & 'column_x3']\n",
    "df['column_y'] = df['column_y'].apply(bool)\n",
    "df['column_y'] = df['column_y'].apply(int)\n",
    "#Create a new True/False column according to the first letter on another column.\n",
    "lEI = [0] * df.shape[0]\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    try:\n",
    "        l = df['room_list'].iloc[i].split(', ')\n",
    "    except:\n",
    "        #When the given row is empty\n",
    "        l = []\n",
    "    for element in l:\n",
    "        if element[0] == 'E' or element[0] == 'I':\n",
    "            lEI[i] = 1\n",
    "\n",
    "df['EI'] = pd.Series(lEI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "df_norm = pd.DataFrame(scaler.transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply all the same transformations to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Validation method\n",
    "#Train and validation set split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop('target_var', axis=1)\n",
    "y = df['column to predict']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.4, stratify = y.values, random_state = 101)\n",
    "#Cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X, y, cv=5)\n",
    "#StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, random_state=101)\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train many quick and dirty models from different categories(e.g., linear, naive Bayes, SVM, Random Forests, neural net, etc.) using standard parameters.\n",
    "#########\n",
    "# Linear Regression\n",
    "#########\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "#Linear model interpretation\n",
    "lr.intercept_\n",
    "lr.coef_\n",
    "\n",
    "#Use model to predict\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "#Evaluate accuracy of the model\n",
    "plt.scatter(y_val, y_pred) #should have the shape of a line for good predictions\n",
    "sns.distplot(y_val - y_pred) #should be a normal distribution centered at 0\n",
    "acc_lr = round(lr.score(X_val, y_val) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Logistic Regression\n",
    "#########\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "\n",
    "#Use model to predict\n",
    "y_pred = logmodel.predict(X_val)\n",
    "\n",
    "#Evaluate accuracy of the model\n",
    "acc_log = round(logmodel.score(X_val, y_val) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# KNN\n",
    "#########\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Use model to predict\n",
    "y_pred = knn.predict(X_val)\n",
    "\n",
    "#Evaluate accuracy of the model\n",
    "acc_knn = round(knn.score(X_val, y_val) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Decision Tree\n",
    "#########\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "#Use model to predict\n",
    "y_pred = dtree.predict(X_val)\n",
    "\n",
    "#Evaluate accuracy of the model\n",
    "acc_dtree = round(dtree.score(X_val, y_val) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Random Forest\n",
    "#########\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=200, random_state=101, n_jobs=-1, verbose=3)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=200, random_state=101, n_jobs=-1, verbose=3)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "#Use model to predict\n",
    "y_pred = rfr.predict(X_val)\n",
    "\n",
    "#Evaluate accuracy of the model\n",
    "acc_rf = round(rfr.score(X_val, y_val) * 100, 2)\n",
    "\n",
    "#Evaluate feature importance\n",
    "importances = rfr.feature_importances_\n",
    "std = np.std([importances for tree in rfr.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "feature_importances = pd.DataFrame(rfr.feature_importances_, index = X_train.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances.sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# lightGBM (LGBM)\n",
    "#########\n",
    "import lightgbm as lgb\n",
    "#create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "#specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "#train\n",
    "gbm = lgb.train(params, lgb_train, num_boost_round=20, valid_sets=lgb_eval, early_stopping_rounds=5)\n",
    "\n",
    "#save model to file\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "#predict\n",
    "y_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# XGBoost\n",
    "#########\n",
    "import xgboost as xgb\n",
    "\n",
    "params = {'objective': 'multi:softmax',  #Specify multiclass classification\n",
    "        'num_class': 9,  #Number of possible output classes\n",
    "        'tree_method': 'hist',  #Use gpu_hist for GPU accelerated algorithm.\n",
    "        'eta': 0.1,\n",
    "        'max_depth': 6,\n",
    "        'silent': 1,\n",
    "        'gamma': 0,\n",
    "        'eval_metric': \"merror\",\n",
    "        'min_child_weight': 3,\n",
    "        'max_delta_step': 1,\n",
    "        'subsample': 0.9,\n",
    "        'colsample_bytree': 0.4,\n",
    "        'colsample_bylevel': 0.6,\n",
    "        'colsample_bynode': 0.5,\n",
    "        'lambda': 0,\n",
    "        'alpha': 0,\n",
    "        'seed': 0}\n",
    "\n",
    "xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "xgval = xgb.DMatrix(X_val, label=y_val)\n",
    "xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "num_rounds = 500\n",
    "gpu_res = {}  #Store accuracy result\n",
    "#Train model\n",
    "xgbst = xgb.train(params, xgtrain, num_rounds, evals=[\n",
    "            (xgval, 'test')], evals_result=gpu_res)\n",
    "\n",
    "y_pred = xgbst.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Support Vector Machine (SVM)\n",
    "#########\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use model to predict\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "#Evaluate accuracy of the model\n",
    "acc_svm = round(model.score(X_val, y_val) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# K-Means Clustering\n",
    "#########\n",
    "#Train model\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=K) #Choose K\n",
    "kmeans.fit(df)\n",
    "#Evaluate the model\n",
    "kmeans.cluster_centers_\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure and compare their performance\n",
    "models = pd.DataFrame({\n",
    "'Model': ['Linear Regression', 'Support Vector Machine', 'KNN', 'Logistic Regression', \n",
    "            'Random Forest'],\n",
    "'Score': [acc_lr, acc_svm, acc_knn, acc_log, \n",
    "            acc_rf]})\n",
    "models.sort_values(by='Score', ascending=False)\n",
    "#Analyze the most significant variables for each algorithm.\n",
    "#Analyze the types of errors the models make.\n",
    "#What data would a human have used to avoid these errors?\n",
    "#Have a quick round of feature selection and engineering.\n",
    "#Have one or two more quick iterations of the five previous steps.\n",
    "#Short-list the top three to five most promising models, preferring models that make different types of errors.\n",
    "#Define Performance Metrics\n",
    "#ROC AUC for classification tasks\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "roc_auc = roc_auc_score(y_val, model.predict(X_val))\n",
    "fpr, tpr, thresholds = roc_curve(y_val, model.predict_proba(X_val)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Model (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_val, y_pred)\n",
    "#MAE, MSE, RMSE\n",
    "from sklearn import metrics\n",
    "metrics.mean_absolute_error(y_val, y_pred)\n",
    "metrics.mean_squared_error(y_val, y_pred)\n",
    "np.sqrt(metrics.mean_squared_error(y_val, y_pred))\n",
    "#Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine-tune the hyperparameters using cross-validation\n",
    "#Treat your data transformation choices as hyperparameters, especially when you are not sure about them (e.g., should I replace missing values with zero or with the median value? Or just drop the rows?)\n",
    "#Unless there are very few hyperparameter values to explore, prefer random search over grid search. If training is very long, you may prefer a Bayesian optimization approach\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C':[0.1,1,10,100,1000], 'gamma':[1,0.1,0.01,0.001,0.0001]}\n",
    "grid = GridSearchCV(model, param_grid, verbose = 3)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try Ensemble methods. Combining your best models will often perform better than running them individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once you are confident about your final model, measure its performance on the test set to estimate the generalization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model interpretability\n",
    "#Feature importance\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(model, random_state=101).fit(X_val, y_val)\n",
    "eli5.show_weights(perm, feature_names = X_val.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partial dependence plot\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "#Create the data that we will plot\n",
    "pdp_goals = pdp.pdp_isolate(model=model, dataset=X_val, model_features=X_val.columns, feature='Goals Scored')\n",
    "\n",
    "#plot it\n",
    "pdp.pdp_plot(pdp_goals, 'Goals Scored')\n",
    "plt.show()\n",
    "\n",
    "#Similar to previous PDP plot except we use pdp_interact instead of pdp_isolate and pdp_interact_plot instead of pdp_isolate_plot\n",
    "features_to_plot = ['Goals Scored', 'Distance Covered (Kms)']\n",
    "inter1  =  pdp.pdp_interact(model=model, dataset=X_val, model_features=X_val.columns, features=features_to_plot)\n",
    "\n",
    "pdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=features_to_plot, plot_type='contour')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Values: Understand how each feature affects every individual prediciton\n",
    "import shap\n",
    "data_for_prediction = X_val.iloc[row_num]\n",
    "explainer = shap.TreeExplainer(model)  #Use DeepExplainer for Deep Learning models, KernelExplainer for all other models\n",
    "shap_vals = explainer.shap_values(data_for_prediction)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_vals[1], data_for_prediction)\n",
    "\n",
    "#We can also do a SHAP plot of the whole dataset\n",
    "shap_vals = explainer.shap_values(X_val)\n",
    "shap.summary_plot(shap_vals[1], X_val)\n",
    "#SHAP Dependence plot\n",
    "shap.dependence_plot('feature_for_x', shap_vals[1], X_val, interaction_index=\"feature_for_color\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
